{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05bfff27-6484-4c9c-9f1a-b6aee6c612be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import stat\n",
    "\n",
    "BATCH_DIR = '/home/ci411/volume_estimation/batched_jobs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f3d341-d628-4bc6-b8f6-6881940bce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import sys\n",
      "sys.path.append(\"/home/ci411/volume_estimation/\")\n",
      "\n",
      "from volume_estimation import modeling\n",
      "import torch\n",
      "import os\n",
      "\n",
      "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "print('Using device:', device)\n",
      "print()\n",
      "\n",
      "MODELS_DIR = '/scratch/ci411/sonos_rirs/models/'\n",
      "FEATURES_DIR = '/scratch/ci411/sonos_rirs/features/'\n",
      "\n",
      "feature_set = 'cool_features'\n",
      "\n",
      "model_dict = {}\n",
      "model_dict['name'] = 'cool_model'\n",
      "model_dict['notes'] = 'testing the formatting'\n",
      "model_dict['data_path'] = os.path.join(FEATURES_DIR, feature_set, 'feature_df.csv')\n",
      "model_dict['model_path'] = os.path.join(MODELS_DIR, 'cool_experiment', model_dict['name'])\n",
      "\n",
      "modeling.train_model(modeling.Baseline_Model, model_dict, epochs=3000, batch_size=64, lr_init=0.0001, l2_reg=0.0001, overwrite=True, log=False, sched_thres=0.001, normalize_targets=True, targets=['thing', 'otherthing'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_script = '''\n",
    "import sys\n",
    "sys.path.append(\"/home/ci411/volume_estimation/\")\n",
    "\n",
    "from volume_estimation import modeling\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "MODELS_DIR = '/scratch/ci411/sonos_rirs/models/'\n",
    "FEATURES_DIR = '/scratch/ci411/sonos_rirs/features/'\n",
    "\n",
    "feature_set = '{feature_set}'\n",
    "\n",
    "model_dict = {{}}\n",
    "model_dict['name'] = '{model_name}'\n",
    "model_dict['notes'] = '{model_notes}'\n",
    "model_dict['data_path'] = os.path.join(FEATURES_DIR, feature_set, 'feature_df.csv')\n",
    "model_dict['model_path'] = os.path.join(MODELS_DIR, '{experiment_name}', model_dict['name'])\n",
    "\n",
    "modeling.train_model(modeling.Baseline_Model, model_dict, epochs={epochs}, batch_size={batch_size}, lr_init={lr_init}, l2_reg={l2_reg}, overwrite=True, log={log}, sched_thres={sched_thres}, normalize_targets={normalize_targets}, targets={targets})\n",
    "'''\n",
    "\n",
    "#keys are feature_set, model_name, model_notes\n",
    "#batch_size, lr_init, l2_reg, log, sched_thres, targets\n",
    "\n",
    "train_script_example = train_script.format(feature_set=\"cool_features\",model_name=\"cool_model\", model_notes=\"testing the formatting\",\\\n",
    "                                           experiment_name='cool_experiment', normalize_targets=True,\\\n",
    "                                           epochs=3000, batch_size=64, lr_init=1e-4, l2_reg=1e-4, log=False, sched_thres=1e-3, targets=[\"thing\", \"otherthing\"])\n",
    "print(train_script_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0fcf4d-4e2d-45fa-a25c-20ef49ae437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --job-name=jobbyjob\n",
      "#SBATCH --nodes=1\n",
      "#SBATCH --cpus-per-task=4\n",
      "#SBATCH --mem=32GB\n",
      "#SBATCH --time=47:59:59\n",
      "#SBATCH --mail-user=chris.ick@nyu.edu\n",
      "#SBATCH --export=NONE\n",
      "#SBATCH --output=\"o_jobbyjob-%j.out\"\n",
      "#SBATCH --gres=gpu:v100:1\n",
      "\n",
      "module purge\n",
      "module load anaconda3/2020.07\n",
      "\n",
      "source /home/ci411/.bashrc\n",
      "conda activate s3d_env\n",
      "python /home/ci411/volume_estimation/batched_jobs/science_time/jobbyjob.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_script = '''#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name={job_name}\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=32GB\n",
    "#SBATCH --time=47:59:59\n",
    "#SBATCH --mail-user=chris.ick@nyu.edu\n",
    "#SBATCH --export=NONE\n",
    "#SBATCH --output=\"o_{job_name}-%j.out\"\n",
    "#SBATCH --gres=gpu:{gre_spec}\n",
    "\n",
    "module purge\n",
    "module load anaconda3/2020.07\n",
    "\n",
    "source /home/ci411/.bashrc\n",
    "conda activate s3d_env\n",
    "python /home/ci411/volume_estimation/batched_jobs/{experiment_name}/{job_name}.py\n",
    "'''\n",
    "\n",
    "test_batch = batch_script.format(job_name=\"jobbyjob\", experiment_name=\"science_time\", gre_spec='v100:1')\n",
    "print(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afdc85d0-9b25-499a-8855-b119202edd6d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-06 1.77827941e-06 3.16227766e-06 5.62341325e-06\n",
      " 1.00000000e-05]\n"
     ]
    }
   ],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 100\n",
    "def_hyp['batch_size'] = 4\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['normalize_targets'] = True\n",
    "def_hyp['targets'] = ['rt60']\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "def_hyp['feature_set'] = '101722_20k/101722_20k_prop1'\n",
    "\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '10255_rt60normlr'\n",
    "run_template = 'learningrate{}_rt60norm_102522'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "learning_rates = np.logspace(-6, -5, 5)\n",
    "print(learning_rates)\n",
    "notes_list = ['lr {}'.format(lr) for lr in learning_rates]\n",
    "\n",
    "runall = \"\"\n",
    "\n",
    "\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    train = train_script.format(feature_set=def_hyp['feature_set'], model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=lr,\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                normalize_targets=def_hyp['normalize_targets'],\\\n",
    "                                experiment_name=experiment_name, targets=def_hyp['targets'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "383e44ed-a015-4b67-a820-e0d9403fac75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-07 2.68269580e-07 7.19685673e-07 1.93069773e-06\n",
      " 5.17947468e-06 1.38949549e-05 3.72759372e-05 1.00000000e-04]\n"
     ]
    }
   ],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 100\n",
    "def_hyp['batch_size'] = 4\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['normalize_targets'] = True\n",
    "def_hyp['targets'] = ['vol']\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "def_hyp['feature_set'] = '101722_20k/101722_20k_prop1'\n",
    "\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '10255_volnormlr'\n",
    "run_template = '{}_volnormlr_102522'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "learning_rates = np.logspace(-7, -4, 8)\n",
    "print(learning_rates)\n",
    "notes_list = ['lr {}'.format(lr) for lr in learning_rates]\n",
    "\n",
    "runall = \"\"\n",
    "\n",
    "\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    train = train_script.format(feature_set=def_hyp['feature_set'], model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=lr,\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                normalize_targets=def_hyp['normalize_targets'],\\\n",
    "                                experiment_name=experiment_name, targets=def_hyp['targets'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "729753cc-9c62-4fdf-ac4c-12a3e0a7956f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-06 1.46779927e-06 2.15443469e-06 3.16227766e-06\n",
      " 4.64158883e-06 6.81292069e-06 1.00000000e-05]\n"
     ]
    }
   ],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 100\n",
    "def_hyp['batch_size'] = 4\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['normalize_targets'] = False\n",
    "def_hyp['targets'] = ['rt60']\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "def_hyp['feature_set'] = '101722_20k/101722_20k_prop1'\n",
    "\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '10255rt60lr'\n",
    "run_template = 'rt60learningrate{}_vol_101922'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "learning_rates = np.logspace(-6, -5, 7)\n",
    "print(learning_rates)\n",
    "notes_list = ['lr {}'.format(lr) for lr in learning_rates]\n",
    "\n",
    "runall = \"\"\n",
    "\n",
    "\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    train = train_script.format(feature_set=def_hyp['feature_set'], model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=lr,\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                normalize_targets=def_hyp['normalize_targets'],\\\n",
    "                                experiment_name=experiment_name, targets=def_hyp['targets'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f522646-a881-4ed8-8626-606b2e4ad7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 4\n",
    "def_hyp['lr_init'] = 5.62341325e-06\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['targets'] = ['rt60']\n",
    "def_hyp['normalize_targets'] = True\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '102422_rt60norm'\n",
    "run_template = 'prop{}_rt60norm_102422'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '101722_20k/101722_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'full phase1: fb phase + mag-feats',\\\n",
    "              'full phase2: fb phase',\\\n",
    "              'replace-cont: mag + lf phase + lf cont',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                normalize_targets=def_hyp['normalize_targets'],\\\n",
    "                                experiment_name=experiment_name, targets=def_hyp['targets'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00edd087-f064-4dc9-9b13-8e7bdea43141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 4\n",
    "def_hyp['lr_init'] = 5.17947468e-06\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['targets'] = ['vol']\n",
    "def_hyp['normalize_targets'] = True\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '102422_volnorm'\n",
    "run_template = 'prop{}_volnorm_102422'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '101722_20k/101722_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'full phase1: fb phase + mag-feats',\\\n",
    "              'full phase2: fb phase',\\\n",
    "              'replace-cont: mag + lf phase + lf cont',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                normalize_targets=def_hyp['normalize_targets'],\\\n",
    "                                experiment_name=experiment_name, targets=def_hyp['targets'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "243c963c-019e-4229-bd51-3ca58cbcd0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001     0.00017783 0.00031623 0.00056234 0.001     ]\n"
     ]
    }
   ],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 100\n",
    "def_hyp['batch_size'] = 4\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['normalize_targets'] = False\n",
    "def_hyp['targets'] = ['vol']\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "def_hyp['feature_set'] = '101722_20k/101722_20k_prop1'\n",
    "\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '1020vollr'\n",
    "run_template = 'learningrate{}_vol_101922'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "learning_rates = np.logspace(-4, -3, 5)\n",
    "print(learning_rates)\n",
    "notes_list = ['lr {}'.format(lr) for lr in learning_rates]\n",
    "\n",
    "runall = \"\"\n",
    "\n",
    "\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    train = train_script.format(feature_set=def_hyp['feature_set'], model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=lr,\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                normalize_targets=def_hyp['normalize_targets'],\\\n",
    "                                experiment_name=experiment_name, targets=def_hyp['targets'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a85af7e-8633-4a11-87a3-bccf5a573883",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.780e-05 2.125e-05 2.470e-05 2.815e-05 3.160e-05]\n"
     ]
    }
   ],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 100\n",
    "def_hyp['batch_size'] = 4\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['normalize_targets'] = True\n",
    "def_hyp['targets'] = ['vol', 'rt60']\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "def_hyp['feature_set'] = '101722_20k/101722_20k_prop1'\n",
    "\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '1020duallr'\n",
    "run_template = 'learningrate{}_dual_101922'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "learning_rates = np.linspace(1.78e-05, 3.16e-05, 5)\n",
    "print(learning_rates)\n",
    "notes_list = ['lr {}'.format(lr) for lr in learning_rates]\n",
    "\n",
    "runall = \"\"\n",
    "\n",
    "\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    train = train_script.format(feature_set=def_hyp['feature_set'], model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=lr,\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                normalize_targets=def_hyp['normalize_targets'],\n",
    "                                experiment_name=experiment_name, targets=def_hyp['targets'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e9bb898-1c8d-4564-8c00-88108d28c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['lr_init'] = 1.85e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['targets'] = ['vol', 'rt60']\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "def_hyp['feature_set'] = '101722_20k/101722_20k_prop1'\n",
    "\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '1019dualbs'\n",
    "run_template = 'batchsize{}_dual_101922'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "batch_sizes = [1,4,16,256,1024,2048,4096]\n",
    "notes_list = ['batch size {}'.format(b) for b in batch_sizes]\n",
    "\n",
    "runall = \"\"\n",
    "\n",
    "\n",
    "for i, batch_size in enumerate(batch_sizes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    train = train_script.format(feature_set=def_hyp['feature_set'], model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=batch_size,lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, targets=def_hyp['targets'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a023cf32-9c22-46d4-813c-596259d52eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batch size 1', 'batch size 4', 'batch size 16', 'batch size 256', 'batch size 1024', 'batch size 2048', 'batch size 4096']\n"
     ]
    }
   ],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['lr_init'] = 1.85e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['targets'] = ['vol']\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "def_hyp['feature_set'] = '101722_20k/101722_20k_prop1'\n",
    "\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '1019volbs'\n",
    "run_template = 'batchsize{}_vol_101922'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "batch_sizes = [1,4,16,256,1024,2048,4096]\n",
    "notes_list = ['batch size {}'.format(b) for b in batch_sizes]\n",
    "\n",
    "runall = \"\"\n",
    "\n",
    "\n",
    "for i, batch_size in enumerate(batch_sizes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    train = train_script.format(feature_set=def_hyp['feature_set'], model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=batch_size,lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, targets=def_hyp['targets'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f392c417-74ff-45d1-9f37-7455b319b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 4\n",
    "def_hyp['lr_init'] = 1e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['normalize_targets'] = False\n",
    "def_hyp['targets'] = ['rt60']\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '101222_rt60'\n",
    "run_template = 'prop{}_rt60_101222'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '101722_20k/101722_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'full phase1: fb phase + mag-feats',\\\n",
    "              'full phase2: fb phase',\\\n",
    "              'replace-cont: mag + lf phase + lf cont',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                normalize_targets=def_hyp['normalize_targets'],\\\n",
    "                                experiment_name=experiment_name, targets=def_hyp['targets'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d648a113-7969-46e2-b381-9ba656bf213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 4\n",
    "def_hyp['lr_init'] = 0.00017783\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['targets'] = ['vol']\n",
    "def_hyp['normalize_targets'] = False\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '101222_vol'\n",
    "run_template = 'prop{}_vol_101222'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '101722_20k/101722_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'full phase1: fb phase + mag-feats',\\\n",
    "              'full phase2: fb phase',\\\n",
    "              'replace-cont: mag + lf phase + lf cont',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                normalize_targets=def_hyp['normalize_targets'],\\\n",
    "                                experiment_name=experiment_name, targets=def_hyp['targets'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33cfb2cb-ab10-4fda-b3db-41d73674446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 4\n",
    "def_hyp['lr_init'] = 2.815e-05\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['targets'] = ['vol', 'rt60']\n",
    "def_hyp['normalize_targets'] = True\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '101222_dual'\n",
    "run_template = 'prop{}_dual_101222'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '101722_20k/101722_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'full phase1: fb phase + mag-feats',\\\n",
    "              'full phase2: fb phase',\\\n",
    "              'replace-cont: mag + lf phase + lf cont',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                normalize_targets=def_hyp['normalize_targets'],\\\n",
    "                                experiment_name=experiment_name, targets=def_hyp['targets'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5ab0ea0-4d47-4903-a9ae-c55e7de9e9e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m notes \u001b[38;5;241m=\u001b[39m notes_list[i]\n\u001b[1;32m     37\u001b[0m feature_set \u001b[38;5;241m=\u001b[39m feature_set_template\u001b[38;5;241m.\u001b[39mformat(idx)\n\u001b[0;32m---> 38\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_script\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmodel_notes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnotes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr_init\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                            \u001b[49m\u001b[43ml2_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml2_reg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msched_thres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msched_thres\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt60\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch_script\u001b[38;5;241m.\u001b[39mformat(job_name\u001b[38;5;241m=\u001b[39mjob_name, experiment_name\u001b[38;5;241m=\u001b[39mexperiment_name, gre_spec\u001b[38;5;241m=\u001b[39mdef_hyp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgre_spec\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     47\u001b[0m train_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(experiment_dir, job_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'targets'"
     ]
    }
   ],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 4\n",
    "def_hyp['lr_init'] = 1.85e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .1\n",
    "def_hyp['target'] = 'rt60'\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '081922_rt60_comp'\n",
    "run_template = 'prop{}_rt60_081922'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '081522_20k/081822_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'full phase1: fb phase + mag-feats',\\\n",
    "              'full phase2: fb phase',\\\n",
    "              'replace-cont: mag + lf phase + lf cont',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target='rt60')\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7501f3d-bc12-4360-91f2-bf2f8aaa2027",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m experiment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m081922_rt60_comp\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m run_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_rt60_081922\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 17\u001b[0m experiment_dir \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BATCH_DIR, experiment_name)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(experiment_dir):\n\u001b[1;32m     20\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(experiment_dir)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 128\n",
    "def_hyp['lr_init'] = 2e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .01\n",
    "def_hyp['target'] = 'rt60'\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '081922_rt60_comp'\n",
    "run_template = 'prop{}_rt60_081922'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '081522_20k/081822_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'full phase1: fb phase + mag-feats',\\\n",
    "              'full phase2: fb phase',\\\n",
    "              'replace-cont: mag + lf phase + lf cont',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target='rt60')\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f99d81f-d39f-4ccb-9dcc-fdeda504215d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m notes \u001b[38;5;241m=\u001b[39m notes_list[i]\n\u001b[1;32m     36\u001b[0m feature_set \u001b[38;5;241m=\u001b[39m feature_set_template\u001b[38;5;241m.\u001b[39mformat(idx)\n\u001b[0;32m---> 37\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_script\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmodel_notes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnotes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr_init\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                            \u001b[49m\u001b[43ml2_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml2_reg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msched_thres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msched_thres\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdef_hyp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch_script\u001b[38;5;241m.\u001b[39mformat(job_name\u001b[38;5;241m=\u001b[39mjob_name, experiment_name\u001b[38;5;241m=\u001b[39mexperiment_name, gre_spec\u001b[38;5;241m=\u001b[39mdef_hyp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgre_spec\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     46\u001b[0m train_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(experiment_dir, job_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'targets'"
     ]
    }
   ],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 128\n",
    "def_hyp['lr_init'] = 1.85e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .01\n",
    "def_hyp['target'] = 'vol'\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '081822_comp'\n",
    "run_template = 'prop{}_20k_081822'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '081522_20k/081822_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'full phase1: fb phase + mag-feats',\\\n",
    "              'full phase2: fb phase',\\\n",
    "              'replace-cont: mag + lf phase + lf cont',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target=def_hyp['target'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96487616-763e-4daf-9095-35685c1d486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 128\n",
    "def_hyp['lr_init'] = 1.85e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .01\n",
    "def_hyp['target'] = 'vol'\n",
    "def_hyp['gre_spec'] = 'v100:1'\n",
    "\n",
    "#comparison models\n",
    "experiment_name = '081822_2_comp'\n",
    "run_template = 'prop{}_20k_081522'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "indexes = [0,1,2,3,4,5,6]\n",
    "feature_set_template = '081522_20k/081522_20k_prop{}'\n",
    "runall = \"\"\n",
    "\n",
    "notes_list = ['baseline: mag + mag-feats',\\\n",
    "              'best model: mag + lf phase + lf 1st deriv',\\\n",
    "              'ablation 1: lf phase + lf 1st deriv',\\\n",
    "              'ablation 2: mag + lf 1st deriv',\\\n",
    "              'ablation 3: mag + lf phase',\\\n",
    "              'base-cont: mag + mag-feats + lf cont',\\\n",
    "              'best-cont: mag + lf phase + lf 1st deriv + lf cont']\n",
    "\n",
    "for i, idx in enumerate(indexes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = notes_list[i]\n",
    "    feature_set = feature_set_template.format(idx)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=def_hyp['epochs'],\\\n",
    "                                batch_size=def_hyp['batch_size'],lr_init=def_hyp['lr_init'],\\\n",
    "                                l2_reg=def_hyp['l2_reg'], log=def_hyp['log'],\\\n",
    "                                sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target=def_hyp['target'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec=def_hyp['gre_spec'])\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfcbe880-5967-43e9-9b47-7239534edbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set default hyperparameters\n",
    "def_hyp = {}\n",
    "def_hyp['epochs'] = 1000\n",
    "def_hyp['batch_size'] = 128\n",
    "def_hyp['lr_init'] = 2e-5\n",
    "def_hyp['l2_reg'] = 1.67e-3\n",
    "def_hyp['log'] = True\n",
    "def_hyp['sched_thres'] = .01\n",
    "def_hyp['target'] = 'rt60'\n",
    "def_hyp['gre_spec'] = 'v100:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23f3247a-4f41-4fc3-b616-088b82907ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vary batch size on baseline model\n",
    "experiment_name = '082222_batch_size'\n",
    "run_template = 'bs_0822{}'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "batch_sizes = [16,32,64,128,256,512,1028]\n",
    "feature_set = '081522_20k/081822_20k_prop1'\n",
    "runall = \"\"\n",
    "\n",
    "for i, bs in enumerate(batch_sizes):\n",
    "    job_name = run_template.format(i)\n",
    "    notes = \"varying batch size on baseline w/ batch_size {}\".format(bs)\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=100, batch_size=bs,\\\n",
    "                                lr_init=def_hyp['lr_init'], l2_reg=def_hyp['l2_reg'],\\\n",
    "                                log=def_hyp['log'], sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target=def_hyp['target'])\n",
    "    \n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec='1')\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d27df0a-f0dc-4f17-8ab6-5adbefbc1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vary inital learning rate on baseline model\n",
    "experiment_name = '082222_learning_rate'\n",
    "run_template = 'lr_0822{}'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "feature_set = '081522_20k/081822_20k_prop1'\n",
    "runall = \"\"\n",
    "    \n",
    "#set variations\n",
    "learning_rates = np.logspace(-1, -8, 8)\n",
    "\n",
    "#adjust iteration\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    job_name = run_template.format(i)\n",
    "    #rewrite notes\n",
    "    notes = \"varying initial learning rate w/ lr = {}\".format(lr)\n",
    "    #adjust parameter inputs\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=300, batch_size=def_hyp['batch_size'],\\\n",
    "                                lr_init=lr, l2_reg=def_hyp['l2_reg'],\\\n",
    "                                log=def_hyp['log'], sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target=def_hyp['target'])\n",
    "    \n",
    "    #clear down\n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec='1')\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aad5f4f0-8bc7-40f7-853b-234c8b21b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vary l2 reg on baseline model\n",
    "experiment_name = '082222_l2_reg'\n",
    "run_template = 'l2_0822{}'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "feature_set = '081522_20k/081822_20k_prop1'\n",
    "runall = \"\"\n",
    "    \n",
    "#set variations\n",
    "reg_lambdas = np.logspace(-1, -5, 6)\n",
    "\n",
    "#adjust iteration\n",
    "for i, l2 in enumerate(reg_lambdas):\n",
    "    job_name = run_template.format(i)\n",
    "    #rewrite notes\n",
    "    notes = \"varying l2 reg parameter w/ lambda {}\".format(l2)\n",
    "    #adjust parameter inputs\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=500, batch_size=def_hyp['batch_size'],\\\n",
    "                                lr_init=def_hyp['lr_init'], l2_reg=l2,\\\n",
    "                                log=def_hyp['log'], sched_thres=def_hyp['sched_thres'],\\\n",
    "                                experiment_name=experiment_name, target=def_hyp['target'])\n",
    "    \n",
    "    #clear down\n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec='1')\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c13f04a-5ed8-454f-87e7-aa735f062b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vary scheduler threshold on baseline model\n",
    "experiment_name = '082222_sched_thres'\n",
    "run_template = 'st_0822{}'\n",
    "\n",
    "experiment_dir = os.path.join(BATCH_DIR, experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "feature_set = '081522_20k/081822_20k_prop1'\n",
    "runall = \"\"\n",
    "    \n",
    "#set variations\n",
    "thresholds = np.logspace(-3,-8, 5)\n",
    "\n",
    "#adjust iteration\n",
    "for i, th in enumerate(thresholds):\n",
    "    job_name = run_template.format(i)\n",
    "    #rewrite notes\n",
    "    notes = \"varying scheduler thresholds with threshold {}\".format(th)\n",
    "    #adjust parameter inputs\n",
    "    train = train_script.format(feature_set=feature_set, model_name=job_name,\\\n",
    "                                model_notes=notes, epochs=500, batch_size=def_hyp['batch_size'],\\\n",
    "                                lr_init=def_hyp['lr_init'], l2_reg=def_hyp['l2_reg'],\\\n",
    "                                log=def_hyp['log'], sched_thres=th,\\\n",
    "                                experiment_name=experiment_name, target=def_hyp['target'])\n",
    "    \n",
    "    #clear down\n",
    "    batch = batch_script.format(job_name=job_name, experiment_name=experiment_name, gre_spec='1')\n",
    "    \n",
    "    train_path = os.path.join(experiment_dir, job_name + '.py')\n",
    "    batch_path = os.path.join(experiment_dir, job_name + '.sbatch')\n",
    "    runall_path = os.path.join(experiment_dir, 'runall.bat')\n",
    "    \n",
    "    runall += \"sbatch {}\\n\".format(batch_path)\n",
    "    \n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write(train)\n",
    "        \n",
    "    with open(batch_path, 'w') as f:\n",
    "        f.write(batch)\n",
    "    \n",
    "    with open(runall_path, 'w') as f:\n",
    "        f.write(runall)\n",
    "        \n",
    "    st = os.stat(runall_path)\n",
    "    os.chmod(runall_path, st.st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b748703f-91a1-4f3f-98ca-95a5e283ba1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-03, 5.62341325e-05, 3.16227766e-06, 1.77827941e-07,\n",
       "       1.00000000e-08])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = np.logspace(-3,-8, 5)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ced3d-7f99-4766-a56a-b75de8449874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
